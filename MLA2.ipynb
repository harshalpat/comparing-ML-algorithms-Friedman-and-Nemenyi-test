{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd \n\nurl='https://archive.ics.uci.edu/ml/machine-learning-databases/spambase/spambase.data'\ndata=pd.read_csv(url)","execution_count":1,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X=data.iloc[:,:-1]# rest of data\ny=data.iloc[:,-1]# target data ","execution_count":2,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import classification_report,accuracy_score\nfrom sklearn import svm\nimport math\nfrom sklearn.metrics import confusion_matrix\n\nfrom sklearn.neighbors import KNeighborsClassifier\n\nimport time\nfolds=StratifiedKFold(n_splits=10)\nfolds.get_n_splits(X, y)","execution_count":3,"outputs":[{"output_type":"execute_result","execution_count":3,"data":{"text/plain":"10"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"def  SupportVectorMachine(X_train,y_train,y_test, X_test,i):\n\n    \n     svmclf = svm.SVC(gamma = 'scale')  #linear,polynomial,radial basis function(rbf) and sigmoid\n\n     svmclf.fit(X_train,y_train)\n    \n     y_predict = svmclf.predict(X_test)\n        \n     tn_svm,fp_svm,fn_svm,tp_svm=confusion_matrix(y_test, y_predict).ravel()\n     \n     Accuracy[i].append((tp_svm+tn_svm)/(tn_svm+fp_svm+fn_svm+tp_svm))\n    \n     recall=(tp_svm)/(tp_svm+fn_svm)\n        \n     precision=(tp_svm)/(tp_svm+fp_svm)\n    \n     Fmeasure[i].append((2*recall*precision)/(recall+precision))\n    \n    \n    \n    ","execution_count":4,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def KNNeighborsAlgorithm(X_train,y_train,y_test, X_test,i):\n   \n    knn = KNeighborsClassifier(n_neighbors=5, metric='euclidean')\n\n    knn.fit(X_train, y_train)\n\n    y_pred = knn.predict(X_test)\n    \n    tn_knn,fp_knn,fn_knn,tp_knn=confusion_matrix(y_test, y_pred).ravel()\n     \n    Accuracy[i].append((tp_knn+tn_knn)/(tn_knn+fp_knn+fn_knn+tp_knn))\n    \n    recall=(tp_knn)/(tp_knn+fn_knn)\n        \n    precision=(tp_knn)/(tp_knn+fp_knn)\n    \n    Fmeasure[i].append((2*recall*precision)/(recall+precision))\n    \n    \n    ","execution_count":35,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def randomForest(X_train,y_train,y_test, X_test,i):\n    \n     model=RandomForestClassifier()\n\n     model.fit(X_train,y_train)\n\n     y_pred=model.predict(X_test)\n        \n     tn_rf,fp_rf,fn_rf,tp_rf=confusion_matrix(y_test, y_pred).ravel()\n     \n     Accuracy[i].append((tp_rf+tn_rf)/(tn_rf+fp_rf+fn_rf+tp_rf))\n    \n     recall=(tp_rf)/(tp_rf+fn_rf)\n        \n     precision=(tp_rf)/(tp_rf+fp_rf)\n    \n     Fmeasure[i].append((2*recall*precision)/(recall+precision))\n        \n     ","execution_count":36,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"i=0\nAccuracy=[]\nFmeasure=[]\nComputationaltrainingtime=[]\n\n\nfor train_index, test_index in folds.split(X,y):\n   \n   \n    y_train=data.iloc[train_index,57].values.tolist()\n\n    X_train=data.iloc[train_index,0:57].values.tolist()\n\n    y_test=data.iloc[test_index,57].values.tolist()\n\n    X_test=data.iloc[test_index,0:57].values.tolist()\n    \n    Accuracy.append([])\n    \n    Fmeasure.append([])\n    \n    Computationaltrainingtime.append([])\n    \n    # SVM classifier\n    \n    t1=time.time()  #time when training starts in seconds\n    \n    SupportVectorMachine(X_train,y_train,y_test, X_test,i)\n    \n    t2=time.time()-t1  #training ended and difference is calculated\n    \n    Computationaltrainingtime[i].append(t2)\n     #Knn classifier\n        \n    \n    t1=time.time()\n    \n    KNNeighborsAlgorithm(X_train,y_train,y_test, X_test,i)\n    \n    t2=time.time()-t1\n    \n    Computationaltrainingtime[i].append(t2)\n    \n     #random forest\n        \n   \n    t1=time.time()\n    \n    randomForest(X_train,y_train,y_test, X_test,i)\n    \n    t2=time.time()-t1\n    \n    Computationaltrainingtime[i].append(t2)\n    \n    i=i+1","execution_count":37,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Accuracy","execution_count":38,"outputs":[{"data":{"text/plain":"[[0.6608695652173913, 0.741304347826087, 0.9543478260869566],\n [0.65, 0.7739130434782608, 0.9456521739130435],\n [0.7304347826086957, 0.7804347826086957, 0.9369565217391305],\n [0.7521739130434782, 0.8217391304347826, 0.9521739130434783],\n [0.7043478260869566, 0.8108695652173913, 0.9565217391304348],\n [0.6804347826086956, 0.8217391304347826, 0.9565217391304348],\n [0.758695652173913, 0.8195652173913044, 0.9695652173913043],\n [0.7065217391304348, 0.8282608695652174, 0.9717391304347827],\n [0.7543478260869565, 0.7239130434782609, 0.8934782608695652],\n [0.7086956521739131, 0.7630434782608696, 0.8586956521739131]]"},"execution_count":38,"metadata":{},"output_type":"execute_result"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"Fmeasure","execution_count":39,"outputs":[{"data":{"text/plain":"[[0.48344370860927155, 0.6570605187319885, 0.9408450704225353],\n [0.48231511254019294, 0.7094972067039107, 0.9303621169916434],\n [0.5571428571428572, 0.7089337175792508, 0.9159420289855073],\n [0.6274509803921569, 0.757396449704142, 0.9375],\n [0.5342465753424658, 0.7603305785123967, 0.9438202247191012],\n [0.5211726384364821, 0.7771739130434783, 0.9456521739130435],\n [0.6185567010309279, 0.7461773700305812, 0.9604519774011299],\n [0.5454545454545454, 0.7799442896935934, 0.9635854341736695],\n [0.5890909090909091, 0.6718346253229975, 0.870026525198939],\n [0.541095890410959, 0.7029972752043596, 0.8179271708683474]]"},"execution_count":39,"metadata":{},"output_type":"execute_result"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"def  FriedmenTestandNemeyiTest(Accuracy,S):# S is used to differ the ranking of time and accuracy, fmeasure\n    rank=[]\n    j=0\n    mean_of_rank_svm=0\n    mean_of_rank_knn=0\n    mean_of_rank_rf=0\n\n    for row in Accuracy:\n      rank.append([])\n      for i in range(0,len(row)):\n            rank[j].append(0)\n      if S==0:\n        if (row[0]-row[1])>0:\n             if (row[0]-row[2])>0:\n                    rank[j][0]=1   # ranking for accuracy n fmeasure\n                    if (row[2]-row[1])>0:\n                        rank[j][2]=2\n                        rank[j][1]=3\n                    else:\n                        rank[j][1]=2\n                        rank[j][2]=3\n             else:\n                    rank[j][2]=1\n                    rank[j][0]=2\n                    rank[j][1]=3\n        else:\n            if(row[1]-row[2])>0:\n                rank[j][1]=1\n                if(row[0]-row[2])>0:\n                    rank[j][0]=2\n                    rank[j][2]=3\n                else:\n                    rank[j][0]=3\n                    rank[j][2]=2\n            else:\n                rank[j][2]=1\n                rank[j][1]=2\n                rank[j][0]=3\n    \n        mean_of_rank_svm=mean_of_rank_svm+rank[j][0]\n        mean_of_rank_knn=mean_of_rank_knn+rank[j][1]\n        mean_of_rank_rf=mean_of_rank_rf+rank[j][2]\n        j=j+1\n      else:\n        if (row[0]-row[1])>0:\n             if (row[0]-row[2])>0:\n                    rank[j][0]=3   #ranking for time (in reverse)\n                    if (row[2]-row[1])>0:\n                        rank[j][2]=2\n                        rank[j][1]=1\n                    else:\n                        rank[j][1]=2\n                        rank[j][2]=1\n             else:\n                    rank[j][2]=3\n                    rank[j][0]=2\n                    rank[j][1]=1\n        else:\n            if(row[1]-row[2])>0:\n                rank[j][1]=3\n                if(row[0]-row[2])>0:\n                    rank[j][0]=2\n                    rank[j][2]=1\n                else:\n                    rank[j][0]=1\n                    rank[j][2]=2\n            else:\n                rank[j][2]=3\n                rank[j][1]=2\n                rank[j][0]=1\n    \n        mean_of_rank_svm=mean_of_rank_svm+rank[j][0]\n        mean_of_rank_knn=mean_of_rank_knn+rank[j][1]\n        mean_of_rank_rf=mean_of_rank_rf+rank[j][2]\n        j=j+1\n    mean_of_rank_svm=mean_of_rank_svm/10\n    mean_of_rank_knn=mean_of_rank_knn/10\n    mean_of_rank_rf=mean_of_rank_rf/10\n    \n    print(\"Fold\",end=\" \")\n    print(\"SupportVectorMachine\",end=\"  \")\n    print(\"KNN\",end=\"            \")\n    print(\"Random Forest\")\n    for j in range(0,10):\n        if j!=9:\n           print(j+1,end=\"        \")\n        else:\n           \n           print(j+1,end=\"       \")\n        for i in range(0,3):\n           print(\"%.2f\" % round(Accuracy[j][i],2),end=\" \")\n    \n           print('({:1d})'.format(rank[j][i]),end=\"         \")\n        print()\n    print(\"\")    \n    print(\"avearge rank\",end=\"  \")\n    print(mean_of_rank_svm,end=\"        \")\n    print(mean_of_rank_knn,end=\"          \")\n    print(mean_of_rank_rf)\n   \n    k=3\n    #k=3 is 3 Algorithms \n    AR=(k+1)/2\n\n    #SD is Sum of Squared differences\n    SD=10*((mean_of_rank_svm-AR)*(mean_of_rank_svm-AR)+(mean_of_rank_knn-AR)*(mean_of_rank_knn-AR)+(mean_of_rank_rf-AR)*(mean_of_rank_rf-AR)) \n    \n    \n    if (SD<7.8):\n        \n        print(\"accept null hypothesis all three algorithms perform same \")\n    else:\n        print(\"reject null hypothesis all three algorithms perform differently\")\n        \n    qalpha=2.343\n    n=10\n    CD=qalpha*(math.sqrt( (k*(k+1))/(6*n) ) )\n    \n    \n    print(\"Critical difference for Nemenyi test is \",CD)\n    \n    \n    if abs(mean_of_rank_svm-mean_of_rank_rf)>CD:\n       print(\"SVM and random forest perform algorithms differently exceeds critical difference \")\n    if abs(mean_of_rank_knn-mean_of_rank_svm)>CD:\n       print(\"Knn and SVM perform algorithms differently exceeds critical difference \") \n    if abs(mean_of_rank_knn-mean_of_rank_rf)>CD:\n       print(\"Knn and random forest perform algorithms differently exceed critical difference\") \n    \n    ","execution_count":40,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nFriedmenTestandNemeyiTest(Accuracy,0)","execution_count":41,"outputs":[{"name":"stdout","output_type":"stream","text":"Fold SupportVectorMachine  KNN            Random Forest\n1        0.66 (3)         0.74 (2)         0.95 (1)         \n2        0.65 (3)         0.77 (2)         0.95 (1)         \n3        0.73 (3)         0.78 (2)         0.94 (1)         \n4        0.75 (3)         0.82 (2)         0.95 (1)         \n5        0.70 (3)         0.81 (2)         0.96 (1)         \n6        0.68 (3)         0.82 (2)         0.96 (1)         \n7        0.76 (3)         0.82 (2)         0.97 (1)         \n8        0.71 (3)         0.83 (2)         0.97 (1)         \n9        0.75 (2)         0.72 (3)         0.89 (1)         \n10       0.71 (3)         0.76 (2)         0.86 (1)         \n\navearge rank  2.9        2.1          1.0\nreject null hypothesis all three algorithms perform differently\nCritical difference for Nemenyi test is  1.0478214542564015\nSVM and random forest perform algorithms differently exceeds critical difference \nKnn and random forest perform algorithms differently exceed critical difference\n"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"FriedmenTestandNemeyiTest(Fmeasure,0)","execution_count":42,"outputs":[{"name":"stdout","output_type":"stream","text":"Fold SupportVectorMachine  KNN            Random Forest\n1        0.48 (3)         0.66 (2)         0.94 (1)         \n2        0.48 (3)         0.71 (2)         0.93 (1)         \n3        0.56 (3)         0.71 (2)         0.92 (1)         \n4        0.63 (3)         0.76 (2)         0.94 (1)         \n5        0.53 (3)         0.76 (2)         0.94 (1)         \n6        0.52 (3)         0.78 (2)         0.95 (1)         \n7        0.62 (3)         0.75 (2)         0.96 (1)         \n8        0.55 (3)         0.78 (2)         0.96 (1)         \n9        0.59 (3)         0.67 (2)         0.87 (1)         \n10       0.54 (3)         0.70 (2)         0.82 (1)         \n\navearge rank  3.0        2.0          1.0\nreject null hypothesis all three algorithms perform differently\nCritical difference for Nemenyi test is  1.0478214542564015\nSVM and random forest perform algorithms differently exceeds critical difference \n"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"FriedmenTestandNemeyiTest(Computationaltrainingtime,1)","execution_count":43,"outputs":[{"name":"stdout","output_type":"stream","text":"Fold SupportVectorMachine  KNN            Random Forest\n1        2.03 (3)         0.09 (1)         0.90 (2)         \n2        1.82 (3)         0.08 (1)         0.81 (2)         \n3        1.75 (3)         0.07 (1)         0.81 (2)         \n4        1.78 (3)         0.07 (1)         0.81 (2)         \n5        1.81 (3)         0.07 (1)         0.81 (2)         \n6        1.83 (3)         0.07 (1)         0.86 (2)         \n7        1.82 (3)         0.07 (1)         0.85 (2)         \n8        1.83 (3)         0.08 (1)         0.87 (2)         \n9        1.80 (3)         0.07 (1)         0.80 (2)         \n10       1.81 (3)         0.07 (1)         0.81 (2)         \n\navearge rank  3.0        1.0          2.0\nreject null hypothesis all three algorithms perform differently\nCritical difference for Nemenyi test is  1.0478214542564015\nKnn and SVM perform algorithms differently exceeds critical difference \n"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.6.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":2}